{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "token embedding --> positional embedding --> dropout --> layernorm --> attn --> dropout --> shortcut --> layernorm --> ff --> dropout --> shortcut --> layernorm --> linear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  40,  367, 2885, 1464, 1807, 3619]])\n",
      "tensor([[ 367, 2885, 1464, 1807, 3619,  402]])\n"
     ]
    }
   ],
   "source": [
    "# define data and tokenizer\n",
    "import tiktoken\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "import torch \n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,txt,tokenizer,max_length,stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        token_ids = tokenizer.encode(txt,allowed_special={\"<|endoftext>\"})\n",
    "        for i in range(0,len(token_ids)-max_length,stride):\n",
    "            input_chunk = token_ids[i:i+max_length]\n",
    "            target_chunk = token_ids[i+1:i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.input_ids[idx],self.target_ids[idx]\n",
    "\n",
    "data_path = 'the-verdict.txt'\n",
    "with open(data_path,'r',encoding='utf-8') as f:\n",
    "    data = f.read()\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "max_length= 6\n",
    "stride = 2\n",
    "my_data = MyDataset(data,tokenizer,max_length,stride)\n",
    "my_dataloader = DataLoader(my_data,batch_size = 1,shuffle=False)\n",
    "data_iter = iter(my_dataloader)\n",
    "inputs,targets = next(data_iter)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'context_length': 1024,\n",
       " 'emb_dim': 768,\n",
       " 'n_heads': 12,\n",
       " 'n_layers': 12,\n",
       " 'drop_rate': 0.1,\n",
       " 'qkv_bias': False}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # maximum context length of GPT model\n",
    "    \"emb_dim\": 768,         # Word Embedding Vector Dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of decoder blocks\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}\n",
    "GPT_CONFIG_124M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenization and positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: \n",
      " torch.Size([1, 6])\n",
      "word embedding: \n",
      " tensor([[[-1.0707,  0.3267,  1.9081,  ...,  1.0112,  0.8606, -0.5563],\n",
      "         [ 0.6871,  0.2658,  0.2954,  ..., -2.8304,  1.3686,  0.3000],\n",
      "         [ 1.1591, -0.6588, -0.1518,  ...,  2.5768,  1.7565, -0.0242],\n",
      "         [ 0.0810, -0.6320,  0.3807,  ...,  0.4548,  0.9513, -2.0836],\n",
      "         [-0.3517,  1.1319,  0.0939,  ...,  1.0578, -1.2894,  0.6249],\n",
      "         [ 1.2559, -0.2192,  1.6321,  ..., -0.4892, -0.3940, -1.0325]]],\n",
      "       grad_fn=<EmbeddingBackward0>) torch.Size([1, 6, 768])\n",
      "positional encoding: \n",
      " tensor([[ 0.5427,  1.1450,  0.6127,  ...,  0.0265,  0.0664, -0.3141],\n",
      "        [-0.2300,  0.0572,  0.4217,  ..., -0.6298,  0.7333,  2.1454],\n",
      "        [ 1.0172,  0.8188, -0.9856,  ...,  0.6877,  1.6905, -0.5306],\n",
      "        [ 0.7248, -0.7288, -1.4576,  ...,  1.6022, -0.9895,  0.0201],\n",
      "        [ 0.0245,  1.0586,  2.1763,  ...,  0.9470,  2.6867, -0.9282],\n",
      "        [ 0.9627,  0.9783,  2.6095,  ...,  0.5074,  0.1534,  0.1154]],\n",
      "       grad_fn=<EmbeddingBackward0>) torch.Size([6, 768])\n",
      "model inputs: \n",
      " tensor([[[-0.5280,  1.4717,  2.5208,  ...,  1.0377,  0.9270, -0.8704],\n",
      "         [ 0.4571,  0.3230,  0.7170,  ..., -3.4602,  2.1020,  2.4454],\n",
      "         [ 2.1763,  0.1600, -1.1374,  ...,  3.2644,  3.4470, -0.5548],\n",
      "         [ 0.8058, -1.3608, -1.0769,  ...,  2.0570, -0.0382, -2.0635],\n",
      "         [-0.3272,  2.1905,  2.2702,  ...,  2.0048,  1.3973, -0.3033],\n",
      "         [ 2.2186,  0.7591,  4.2416,  ...,  0.0182, -0.2406, -0.9171]]],\n",
      "       grad_fn=<AddBackward0>) torch.Size([1, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "print(\"input shape: \\n\",inputs.shape)   # check input\n",
    "\n",
    "token_embedding = nn.Embedding(GPT_CONFIG_124M[\"vocab_size\"],GPT_CONFIG_124M[\"emb_dim\"]) # embedding layer\n",
    "pos_embedding = nn.Embedding(GPT_CONFIG_124M[\"vocab_size\"],GPT_CONFIG_124M[\"emb_dim\"])  # positional encoding layer\n",
    "\n",
    "word_embedding = token_embedding(inputs) #  calculate word embedding\n",
    "pos_encoding = pos_embedding(torch.arange(inputs.shape[-1]))    # calculate positional embedding\n",
    "print(\"word embedding: \\n\",word_embedding,word_embedding.shape)\n",
    "print(\"positional encoding: \\n\",pos_encoding,pos_encoding.shape)\n",
    "\n",
    "model_input_vec = word_embedding + pos_encoding # model input = word embedding + positional embedding\n",
    "print(\"model inputs: \\n\",model_input_vec,model_input_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor after dropout:  tensor([[[-0.5866,  1.6352,  2.8009,  ...,  1.1530,  1.0300, -0.9671],\n",
      "         [ 0.5079,  0.3588,  0.7967,  ..., -3.8446,  2.3355,  2.7171],\n",
      "         [ 2.4181,  0.1777, -1.2638,  ...,  3.6271,  3.8300, -0.0000],\n",
      "         [ 0.8953, -1.5120, -1.1966,  ...,  2.2855, -0.0424, -2.2928],\n",
      "         [-0.3635,  0.0000,  2.5225,  ...,  2.2275,  1.5525, -0.3370],\n",
      "         [ 2.4651,  0.8434,  4.7129,  ...,  0.0202, -0.2673, -1.0190]]],\n",
      "       grad_fn=<MulBackward0>) torch.Size([1, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "dropout_layer = nn.Dropout(GPT_CONFIG_124M[\"drop_rate\"]) #  dropout layer with rate\n",
    "dropout_result = dropout_layer(model_input_vec) # perform dropout, randomly set values to zeros and balance others\n",
    "print(\"tensor after dropout: \",dropout_result,dropout_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[before LayerNorm] mean : tensor([[[ 0.0347],\n",
      "         [-0.0565],\n",
      "         [-0.0055],\n",
      "         [ 0.0346],\n",
      "         [ 0.0132],\n",
      "         [-0.0284]]], grad_fn=<MeanBackward1>)\n",
      "[before LayerNorm] var : tensor([[[1.5070],\n",
      "         [1.4363],\n",
      "         [1.5197],\n",
      "         [1.4435],\n",
      "         [1.5579],\n",
      "         [1.5060]]], grad_fn=<SqrtBackward0>)\n",
      "--------------------------------------------------\n",
      "[after LayerNorm] mean : tensor([[[-3.7253e-09],\n",
      "         [ 1.4901e-08],\n",
      "         [-7.4506e-09],\n",
      "         [ 2.4835e-09],\n",
      "         [ 1.8006e-08],\n",
      "         [-7.4506e-09]]], grad_fn=<MeanBackward1>)\n",
      "[after LayerNorm] var : tensor([[[1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000]]], grad_fn=<SqrtBackward0>)\n",
      "LayerNorm result:  tensor([[[-0.4123,  1.0621,  1.8356,  ...,  0.7421,  0.6605, -0.6648],\n",
      "         [ 0.3929,  0.2892,  0.5940,  ..., -2.6375,  1.6654,  1.9311],\n",
      "         [ 1.5948,  0.1206, -0.8280,  ...,  2.3903,  2.5238,  0.0036],\n",
      "         [ 0.5963, -1.0714, -0.8529,  ...,  1.5594, -0.0534, -1.6123],\n",
      "         [-0.2418, -0.0085,  1.6106,  ...,  1.4213,  0.9881, -0.2248],\n",
      "         [ 1.6557,  0.5789,  3.1483,  ...,  0.0323, -0.1586, -0.6577]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "eps = 1e-5\n",
    "scale = nn.Parameter(torch.ones(GPT_CONFIG_124M[\"emb_dim\"]))\n",
    "shift = nn.Parameter(torch.zeros(GPT_CONFIG_124M[\"emb_dim\"]))\n",
    "\n",
    "mean = dropout_result.mean(dim=-1,keepdim=True) # mean before layerNorm\n",
    "var = dropout_result.var(dim=-1,keepdim=True)   # variance before LayerNorm\n",
    "print(\"[before LayerNorm] mean :\",mean)\n",
    "print(\"[before LayerNorm] var :\",torch.sqrt(var))\n",
    "\n",
    "print(\"-\"*50)\n",
    "\n",
    "layernorm_result_naive = (dropout_result - mean) / torch.sqrt(var + eps)\n",
    "mean = layernorm_result_naive.mean(dim=-1,keepdim=True) # mean after layerNorm\n",
    "var = layernorm_result_naive.var(dim=-1,keepdim=True)   # variance after LayerNorm\n",
    "print(\"[after LayerNorm] mean :\",mean)\n",
    "print(\"[after LayerNorm] var :\",torch.sqrt(var))\n",
    "\n",
    "layernorm_result = scale * layernorm_result_naive + shift\n",
    "print(\"LayerNorm result: \",layernorm_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create QKV Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query matrix:  torch.Size([768, 768])\n",
      "key matrix:  torch.Size([768, 768])\n",
      "value matrix:  torch.Size([768, 768])\n"
     ]
    }
   ],
   "source": [
    "W_query = nn.Linear(GPT_CONFIG_124M[\"emb_dim\"],GPT_CONFIG_124M[\"emb_dim\"],bias = False)\n",
    "W_key = nn.Linear(GPT_CONFIG_124M[\"emb_dim\"],GPT_CONFIG_124M[\"emb_dim\"],bias = False)\n",
    "W_value = nn.Linear(GPT_CONFIG_124M[\"emb_dim\"],GPT_CONFIG_124M[\"emb_dim\"],bias = False)\n",
    "print(\"query matrix: \",W_query.weight.shape)\n",
    "print(\"key matrix: \",W_key.weight.shape)\n",
    "print(\"value matrix: \",W_value.weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Queries\\Keys\\Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queries:  tensor([[[ 0.1639, -0.0128,  1.1365,  ..., -0.4442,  0.6329,  0.2322],\n",
      "         [ 0.1386, -1.2747,  0.1236,  ...,  0.2472,  0.0772,  0.3138],\n",
      "         [ 0.2302, -0.3563, -0.0912,  ...,  0.1018, -0.1375,  0.6736],\n",
      "         [ 0.4807,  0.0962, -0.3384,  ...,  0.3566, -0.1532,  0.7028],\n",
      "         [ 0.3144, -0.2109, -0.5028,  ...,  0.1917,  0.2838, -0.0147],\n",
      "         [-0.1928, -0.0655,  1.1370,  ..., -0.7486, -0.2607, -0.0457]]],\n",
      "       grad_fn=<UnsafeViewBackward0>) torch.Size([1, 6, 768])\n",
      "keys:  tensor([[[-0.7292, -0.1690, -0.6514,  ...,  0.1623,  1.3654,  0.3343],\n",
      "         [-0.9370, -0.6115, -0.0836,  ...,  0.8645, -0.8325,  0.5921],\n",
      "         [ 0.9072, -0.8403,  0.2915,  ...,  0.4051, -0.9864, -0.1795],\n",
      "         [ 0.3510,  1.0415,  1.2674,  ...,  0.1242,  0.1878, -0.9540],\n",
      "         [ 0.4275, -0.8959, -0.2941,  ...,  0.4463, -0.3388, -0.1343],\n",
      "         [-0.1989, -0.0279, -0.1887,  ...,  0.5720,  0.5910, -0.8605]]],\n",
      "       grad_fn=<UnsafeViewBackward0>) torch.Size([1, 6, 768])\n",
      "values:  tensor([[[-0.8907,  0.3944, -0.7370,  ..., -0.0326, -0.5570,  0.4285],\n",
      "         [-0.2022, -0.2141,  0.1248,  ...,  0.5091, -1.4368, -0.0581],\n",
      "         [-0.7406, -0.4258,  0.8561,  ..., -0.7119,  0.5229, -0.5604],\n",
      "         [-0.0442,  0.2451,  0.1057,  ...,  1.0479,  0.3027,  0.0916],\n",
      "         [ 0.8860, -0.1653,  0.1916,  ...,  0.0792, -0.0757,  0.9003],\n",
      "         [-0.2692, -0.0629, -0.0166,  ...,  0.1785,  1.0118,  0.2935]]],\n",
      "       grad_fn=<UnsafeViewBackward0>) torch.Size([1, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "queries = W_query(layernorm_result)\n",
    "keys = W_key(layernorm_result)\n",
    "values = W_value(layernorm_result)\n",
    "print(\"queries: \",queries, queries.shape)\n",
    "print(\"keys: \",keys, keys.shape)\n",
    "print(\"values: \",values, values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Break MultiHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of heads:  64\n",
      "multiheaded queries:  torch.Size([1, 12, 6, 64])\n",
      "multiheaded keys:  torch.Size([1, 12, 6, 64])\n",
      "multiheaded values:  torch.Size([1, 12, 6, 64])\n"
     ]
    }
   ],
   "source": [
    "b,num_tokens,d_in = layernorm_result.shape\n",
    "head_dim = GPT_CONFIG_124M[\"emb_dim\"] // GPT_CONFIG_124M[\"n_heads\"]\n",
    "print('number of heads: ',head_dim)\n",
    "multi_head_queries = queries.view(b,num_tokens,GPT_CONFIG_124M[\"n_heads\"],head_dim)\n",
    "multi_head_keys = keys.view(b,num_tokens,GPT_CONFIG_124M[\"n_heads\"],head_dim)\n",
    "multi_head_values = values.view(b,num_tokens,GPT_CONFIG_124M[\"n_heads\"],head_dim)\n",
    "multi_head_queries_result = multi_head_queries.transpose(1,2)\n",
    "multi_head_keys_result = multi_head_keys.transpose(1,2)\n",
    "multi_head_values_result = multi_head_values.transpose(1,2)\n",
    "print(\"multiheaded queries: \",multi_head_queries_result.shape)\n",
    "print(\"multiheaded keys: \",multi_head_keys_result.shape)\n",
    "print(\"multiheaded values: \",multi_head_values_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Attention Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 6, 6])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores = multi_head_queries_result @ multi_head_keys_result.transpose(2,3)\n",
    "attn_scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask:  tensor([[0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "masked attn score:  tensor([[[[ 3.0475,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 3.4754,  2.5189,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 4.1919, -2.4694,  2.5810,    -inf,    -inf,    -inf],\n",
      "          [ 0.1487, -0.0587,  2.1706, -0.3441,    -inf,    -inf],\n",
      "          [ 2.5241,  0.3745, -1.3315, -0.8973,  2.1271,    -inf],\n",
      "          [ 0.4392,  4.3637,  3.0011,  2.8425, -1.1724, -2.5302]],\n",
      "\n",
      "         [[-1.0943,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 1.1004, -0.2777,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.6079,  1.8770,  3.7414,    -inf,    -inf,    -inf],\n",
      "          [-0.3304, -1.6215, -0.5770,  3.3490,    -inf,    -inf],\n",
      "          [-0.4202, -1.1391,  0.8044, -1.0697,  2.0190,    -inf],\n",
      "          [ 0.2170,  0.1659,  1.3672,  3.5345, -1.0406, -1.2197]],\n",
      "\n",
      "         [[ 0.4803,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 2.6082, -0.0768,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-1.6559,  5.4915,  3.5476,    -inf,    -inf,    -inf],\n",
      "          [ 1.5846, -0.8572, -0.6683,  0.8029,    -inf,    -inf],\n",
      "          [-2.3956, -3.2023, -2.7595, -1.2331,  0.6578,    -inf],\n",
      "          [-0.5573, -2.0796, -2.3767,  0.5090,  0.0505, -0.3113]],\n",
      "\n",
      "         [[-3.4770,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 5.1949,  3.6970,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-1.9997, -7.1973, -3.7030,    -inf,    -inf,    -inf],\n",
      "          [ 0.5159,  3.1712,  1.2651, -2.3363,    -inf,    -inf],\n",
      "          [-1.7229,  0.2445, -0.0660,  2.1099, -2.5103,    -inf],\n",
      "          [-1.3091, -0.9256,  3.9956,  2.0408, -1.9089,  1.2217]],\n",
      "\n",
      "         [[ 1.9093,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 1.8931,  0.1825,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 4.5817,  0.4821, -1.5276,    -inf,    -inf,    -inf],\n",
      "          [ 3.0537, -1.1504, -2.9992,  2.6894,    -inf,    -inf],\n",
      "          [-2.8872, -0.3800,  2.6106, -2.9914, -3.6803,    -inf],\n",
      "          [-2.4856, -2.8792, -3.8115, -3.7926, -3.7901,  1.6030]],\n",
      "\n",
      "         [[-0.6405,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.2115, -2.4472,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-1.3847,  1.7075, -0.7844,    -inf,    -inf,    -inf],\n",
      "          [ 1.1031,  4.8773, -1.3470,  4.7453,    -inf,    -inf],\n",
      "          [ 1.0823, -0.7156, -0.4479,  4.4963,  2.3041,    -inf],\n",
      "          [-2.6858, -3.5223, -0.8576,  2.0711, -0.0957,  1.9763]],\n",
      "\n",
      "         [[-3.3143,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-1.0243,  2.8791,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 3.4764,  6.9940, -0.3440,    -inf,    -inf,    -inf],\n",
      "          [ 2.1401,  0.4254,  3.6051, -2.5343,    -inf,    -inf],\n",
      "          [-2.5690,  3.9341,  1.4669, -2.9672, -0.8349,    -inf],\n",
      "          [ 1.0887, -1.9609, -1.8115, -1.4394,  0.6479, -1.0683]],\n",
      "\n",
      "         [[ 1.9720,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-1.1772, -2.8006,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 4.9064,  1.8370, -0.2377,    -inf,    -inf,    -inf],\n",
      "          [-1.4177,  3.4309, -0.1027,  2.9561,    -inf,    -inf],\n",
      "          [ 6.0202,  3.1461, -2.0072, -0.3927,  0.5912,    -inf],\n",
      "          [-0.9126, -7.1713, -2.3152, -2.2074, -0.6750,  5.2237]],\n",
      "\n",
      "         [[ 0.6154,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-7.6738, -1.0714,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-2.1988, -1.0260, -1.5542,    -inf,    -inf,    -inf],\n",
      "          [-1.7345, -1.6112, -1.1160,  1.9850,    -inf,    -inf],\n",
      "          [-2.5661, -3.4714, -1.2073, -0.5985,  2.7508,    -inf],\n",
      "          [ 1.6990,  1.7860,  0.7942, -1.7579, -1.3239, -0.4289]],\n",
      "\n",
      "         [[ 3.2834,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-1.1211,  0.0895,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 4.2318,  0.1354, -3.4689,    -inf,    -inf,    -inf],\n",
      "          [-1.9556, -1.3778, -0.3525,  1.5257,    -inf,    -inf],\n",
      "          [-3.1499,  0.0952, -2.3108, -1.1540, -1.2516,    -inf],\n",
      "          [ 1.1078,  1.7997, -0.2031, -1.5565, -0.1292, -0.5363]],\n",
      "\n",
      "         [[-4.7343,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-1.1235,  2.1730,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-1.8883, -2.8232, -2.6146,    -inf,    -inf,    -inf],\n",
      "          [-2.5581,  0.2495, -2.6099,  0.7908,    -inf,    -inf],\n",
      "          [-2.3755, -0.5050, -3.3586,  1.9733, -0.3835,    -inf],\n",
      "          [-1.6691,  2.4207,  2.6081, -1.2029,  0.8421, -2.6289]],\n",
      "\n",
      "         [[ 3.7639,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 2.8242, -2.9878,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-1.9702, -2.9846, -0.3835,    -inf,    -inf,    -inf],\n",
      "          [-3.2767, -2.0417, -1.0557,  0.6635,    -inf,    -inf],\n",
      "          [-0.6991, -0.8319,  1.2672, -1.3663, -0.8170,    -inf],\n",
      "          [ 3.6807,  3.8206, -5.8187, -0.5751,  0.6922, -1.3103]]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(num_tokens,num_tokens)*-torch.inf,diagonal=1)\n",
    "print(\"mask: \",mask)\n",
    "masked_attn_scores = attn_scores + mask\n",
    "print(\"masked attn score: \",masked_attn_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Attention Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 6, 6])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_attn_weights = torch.softmax(masked_attn_scores / GPT_CONFIG_124M[\"n_heads\"]**0.5,dim=-1)\n",
    "masked_attn_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Weighted Value of each token in the sequence\n",
    "#### Merging MultiHeads Together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 768])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vec_result = (masked_attn_weights @ multi_head_values_result).transpose(1,2).contiguous()\n",
    "context_vec_result_summing_head = context_vec_result.view(b,num_tokens,GPT_CONFIG_124M[\"emb_dim\"])\n",
    "context_vec_result_summing_head.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multihead attention output:  tensor([[[ 0.1952,  0.5433,  0.4261,  ...,  0.8400,  0.1059, -0.1498],\n",
      "         [ 0.1407,  0.1945,  0.0678,  ...,  0.6771, -0.1707, -0.3266],\n",
      "         [ 0.2719,  0.2131, -0.1079,  ...,  0.5154, -0.0534, -0.1696],\n",
      "         [ 0.0587, -0.2183, -0.2088,  ...,  0.0873,  0.0508, -0.0040],\n",
      "         [ 0.1689, -0.1435, -0.1604,  ..., -0.1684,  0.1032, -0.2286],\n",
      "         [ 0.1441, -0.0958, -0.0515,  ...,  0.0512,  0.0426,  0.0291]]],\n",
      "       grad_fn=<ViewBackward0>) torch.Size([1, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "output_projection = nn.Linear(GPT_CONFIG_124M[\"emb_dim\"],GPT_CONFIG_124M[\"emb_dim\"])\n",
    "multihead_output = output_projection(context_vec_result_summing_head)\n",
    "print(\"multihead attention output: \",multihead_output,multihead_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout result 2:  tensor([[[ 0.2169,  0.6036,  0.4734,  ...,  0.9333,  0.1176, -0.1664],\n",
      "         [ 0.1563,  0.2161,  0.0753,  ...,  0.7523, -0.1897, -0.3629],\n",
      "         [ 0.3021,  0.2368, -0.0000,  ...,  0.5727, -0.0000, -0.1885],\n",
      "         [ 0.0652, -0.2426, -0.2320,  ...,  0.0970,  0.0564, -0.0044],\n",
      "         [ 0.1876, -0.1594, -0.1783,  ..., -0.1871,  0.1146, -0.2541],\n",
      "         [ 0.1601, -0.1064, -0.0572,  ...,  0.0568,  0.0473,  0.0324]]],\n",
      "       grad_fn=<MulBackward0>) torch.Size([1, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "dropout_layer_2 = nn.Dropout(GPT_CONFIG_124M[\"drop_rate\"])\n",
    "dropout_result_2 = dropout_layer_2(multihead_output)\n",
    "print(\"dropout result 2: \",dropout_result_2,dropout_result_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shortcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shortcut result: tensor([[[-0.3697,  2.2389,  3.2743,  ...,  2.0863,  1.1476, -1.1335],\n",
      "         [ 0.6642,  0.5750,  0.8720,  ..., -3.0923,  2.1458,  2.3542],\n",
      "         [ 2.7203,  0.4146, -1.2638,  ...,  4.1998,  3.8300, -0.1885],\n",
      "         [ 0.9605, -1.7545, -1.4286,  ...,  2.3825,  0.0140, -2.2972],\n",
      "         [-0.1759, -0.1594,  2.3442,  ...,  2.0404,  1.6672, -0.5910],\n",
      "         [ 2.6251,  0.7370,  4.6556,  ...,  0.0771, -0.2200, -0.9866]]],\n",
      "       grad_fn=<AddBackward0>) torch.Size([1, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "shortcut_result = dropout_result + dropout_result_2\n",
    "print(\"shortcut result:\", shortcut_result,shortcut_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LayerNorm 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[before LayerNorm] mean : tensor([[[ 0.0311],\n",
      "         [-0.0570],\n",
      "         [-0.0058],\n",
      "         [ 0.0490],\n",
      "         [ 0.0211],\n",
      "         [-0.0200]]], grad_fn=<MeanBackward1>)\n",
      "[before LayerNorm] var : tensor([[[1.5284],\n",
      "         [1.4403],\n",
      "         [1.5326],\n",
      "         [1.4480],\n",
      "         [1.5775],\n",
      "         [1.5077]]], grad_fn=<SqrtBackward0>)\n",
      "--------------------------------------------------\n",
      "[after LayerNorm] mean : tensor([[[-6.2088e-09],\n",
      "         [-8.0715e-09],\n",
      "         [ 8.6923e-09],\n",
      "         [-1.2418e-09],\n",
      "         [-6.2088e-10],\n",
      "         [ 7.4506e-09]]], grad_fn=<MeanBackward1>)\n",
      "[after LayerNorm] var : tensor([[[1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000]]], grad_fn=<SqrtBackward0>)\n",
      "LayerNorm result:  tensor([[[-0.2622,  1.4445,  2.1220,  ...,  1.3447,  0.7305, -0.7620],\n",
      "         [ 0.5007,  0.4388,  0.6450,  ..., -2.1074,  1.5294,  1.6741],\n",
      "         [ 1.7787,  0.2743, -0.8208,  ...,  2.7441,  2.5028, -0.1192],\n",
      "         [ 0.6295, -1.2455, -1.0205,  ...,  1.6115, -0.0242, -1.6203],\n",
      "         [-0.1249, -0.1144,  1.4726,  ...,  1.2801,  1.0435, -0.3880],\n",
      "         [ 1.7544,  0.5020,  3.1011,  ...,  0.0643, -0.1327, -0.6411]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "eps = 1e-5\n",
    "scale_2 = nn.Parameter(torch.ones(GPT_CONFIG_124M[\"emb_dim\"]))\n",
    "shift_2 = nn.Parameter(torch.zeros(GPT_CONFIG_124M[\"emb_dim\"]))\n",
    "\n",
    "mean = shortcut_result.mean(dim=-1,keepdim=True) # mean before layerNorm\n",
    "var = shortcut_result.var(dim=-1,keepdim=True)   # variance before LayerNorm\n",
    "print(\"[before LayerNorm] mean :\",mean)\n",
    "print(\"[before LayerNorm] var :\",torch.sqrt(var))\n",
    "\n",
    "print(\"-\"*50)\n",
    "\n",
    "layernorm_result_naive_2 = (shortcut_result - mean) / torch.sqrt(var + eps)\n",
    "mean = layernorm_result_naive_2.mean(dim=-1,keepdim=True) # mean after layerNorm\n",
    "var = layernorm_result_naive_2.var(dim=-1,keepdim=True)   # variance after LayerNorm\n",
    "print(\"[after LayerNorm] mean :\",mean)\n",
    "print(\"[after LayerNorm] var :\",torch.sqrt(var))\n",
    "\n",
    "layernorm_result_2 = scale_2 * layernorm_result_naive_2 + shift_2\n",
    "print(\"LayerNorm result: \",layernorm_result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first linear layer result:  tensor([[[ 0.1646, -1.8029,  0.1590,  ..., -1.1246, -0.3815,  0.3156],\n",
      "         [-0.8553, -0.3036,  0.3285,  ..., -0.5555, -0.3560,  0.2702],\n",
      "         [ 0.1294, -0.3083, -0.3381,  ..., -0.6389, -0.5909, -0.3548],\n",
      "         [-0.9150,  0.8642,  0.2736,  ..., -0.1818, -0.1741,  0.7490],\n",
      "         [ 1.0397,  1.2555, -0.7647,  ..., -0.1143,  0.2238, -0.4018],\n",
      "         [ 0.5079,  0.7150, -1.6059,  ..., -0.1364,  0.0825, -0.8098]]],\n",
      "       grad_fn=<ViewBackward0>) torch.Size([1, 6, 3072])\n",
      "gelu result:  tensor([[[ 0.0931, -0.0644,  0.0895,  ..., -0.1468, -0.1341,  0.1969],\n",
      "         [-0.1679, -0.1156,  0.2065,  ..., -0.1607, -0.1285,  0.1639],\n",
      "         [ 0.0714, -0.1168, -0.1243,  ..., -0.1671, -0.1639, -0.1282],\n",
      "         [-0.1649,  0.6967,  0.1663,  ..., -0.0778, -0.0750,  0.5789],\n",
      "         [ 0.8843,  1.1239, -0.1700,  ..., -0.0520,  0.1317, -0.1382],\n",
      "         [ 0.3526,  0.5453, -0.0871,  ..., -0.0608,  0.0440, -0.1694]]],\n",
      "       grad_fn=<MulBackward0>) torch.Size([1, 6, 3072])\n",
      "second linear layer result:  tensor([[[ 0.5602,  0.0803, -0.1561,  ...,  0.3931, -0.3835, -0.1509],\n",
      "         [ 0.1856, -0.1699,  0.3808,  ...,  0.1658,  0.3201,  0.1427],\n",
      "         [ 0.3524, -0.0739,  0.1140,  ...,  0.1441, -0.5322, -0.0150],\n",
      "         [ 0.3858,  0.0770,  0.0284,  ...,  0.1411, -0.1399, -0.2582],\n",
      "         [ 0.2528,  0.1441,  0.1965,  ...,  0.1201, -0.2098,  0.0501],\n",
      "         [ 0.4380, -0.0417,  0.0408,  ..., -0.0771,  0.2352, -0.1791]]],\n",
      "       grad_fn=<ViewBackward0>) torch.Size([1, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + torch.tanh(\n",
    "                torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "                (x + 0.044715 * torch.pow(x, 3))\n",
    "            ))\n",
    "ff_1 = nn.Linear(GPT_CONFIG_124M[\"emb_dim\"],4*GPT_CONFIG_124M[\"emb_dim\"])\n",
    "ff_2 = nn.Linear(4 * GPT_CONFIG_124M[\"emb_dim\"],GPT_CONFIG_124M[\"emb_dim\"])\n",
    "ff_1_result = ff_1(layernorm_result_2)\n",
    "print(\"first linear layer result: \",ff_1_result,ff_1_result.shape)\n",
    "gelu_result = gelu(ff_1_result)\n",
    "print(\"gelu result: \",gelu_result,gelu_result.shape)\n",
    "ff_2_result = ff_2(gelu_result)\n",
    "print(\"second linear layer result: \",ff_2_result,ff_2_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout3 result:  tensor([[[ 0.6224,  0.0893, -0.1734,  ...,  0.4368, -0.4262, -0.1677],\n",
      "         [ 0.2062, -0.1888,  0.4231,  ...,  0.1842,  0.3557,  0.1586],\n",
      "         [ 0.3916, -0.0821,  0.1266,  ...,  0.1601, -0.5914, -0.0166],\n",
      "         [ 0.0000,  0.0856,  0.0315,  ...,  0.1568, -0.1555, -0.0000],\n",
      "         [ 0.0000,  0.1601,  0.2183,  ...,  0.1335, -0.2331,  0.0556],\n",
      "         [ 0.4867, -0.0463,  0.0454,  ..., -0.0857,  0.2614, -0.1990]]],\n",
      "       grad_fn=<MulBackward0>) torch.Size([1, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "dropout_layer_3 = nn.Dropout(GPT_CONFIG_124M[\"drop_rate\"])\n",
    "dropout_result_3 = dropout_layer_3(ff_2_result)\n",
    "print(\"Dropout3 result: \",dropout_result_3,dropout_result_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shortcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shortcut result 2: tensor([[[ 2.5274e-01,  2.3281e+00,  3.1009e+00,  ...,  2.5231e+00,\n",
      "           7.2147e-01, -1.3012e+00],\n",
      "         [ 8.7043e-01,  3.8618e-01,  1.2952e+00,  ..., -2.9081e+00,\n",
      "           2.5015e+00,  2.5128e+00],\n",
      "         [ 3.1119e+00,  3.3247e-01, -1.1371e+00,  ...,  4.3599e+00,\n",
      "           3.2386e+00, -2.0509e-01],\n",
      "         [ 9.6054e-01, -1.6690e+00, -1.3971e+00,  ...,  2.5393e+00,\n",
      "          -1.4153e-01, -2.2972e+00],\n",
      "         [-1.7592e-01,  6.4646e-04,  2.5625e+00,  ...,  2.1739e+00,\n",
      "           1.4341e+00, -5.3538e-01],\n",
      "         [ 3.1118e+00,  6.9061e-01,  4.7010e+00,  ..., -8.6216e-03,\n",
      "           4.1355e-02, -1.1856e+00]]], grad_fn=<AddBackward0>) torch.Size([1, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "shortcut_result_2 = shortcut_result + dropout_result_3\n",
    "print(\"shortcut result 2:\",shortcut_result_2,shortcut_result_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[before LayerNorm] mean : tensor([[[ 0.0259],\n",
      "         [-0.0576],\n",
      "         [-0.0041],\n",
      "         [ 0.0461],\n",
      "         [ 0.0246],\n",
      "         [-0.0275]]], grad_fn=<MeanBackward1>)\n",
      "[before LayerNorm] var : tensor([[[1.5469],\n",
      "         [1.4535],\n",
      "         [1.5433],\n",
      "         [1.4591],\n",
      "         [1.6011],\n",
      "         [1.5157]]], grad_fn=<SqrtBackward0>)\n",
      "--------------------------------------------------\n",
      "[after LayerNorm] mean : tensor([[[-1.2418e-08],\n",
      "         [-9.9341e-09],\n",
      "         [ 3.7253e-09],\n",
      "         [-2.4835e-09],\n",
      "         [ 4.3462e-09],\n",
      "         [ 2.4835e-09]]], grad_fn=<MeanBackward1>)\n",
      "[after LayerNorm] var : tensor([[[1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000]]], grad_fn=<SqrtBackward0>)\n",
      "LayerNorm result:  tensor([[[ 0.1466,  1.4883,  1.9879,  ...,  1.6144,  0.4497, -0.8579],\n",
      "         [ 0.6385,  0.3053,  0.9307,  ..., -1.9612,  1.7607,  1.7685],\n",
      "         [ 2.0190,  0.2181, -0.7342,  ...,  2.8277,  2.1011, -0.1303],\n",
      "         [ 0.6267, -1.1754, -0.9891,  ...,  1.7087, -0.1286, -1.6059],\n",
      "         [-0.1252, -0.0150,  1.5850,  ...,  1.3424,  0.8803, -0.3498],\n",
      "         [ 2.0712,  0.4738,  3.1197,  ...,  0.0124,  0.0454, -0.7641]]],\n",
      "       grad_fn=<AddBackward0>) torch.Size([1, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "eps = 1e-5\n",
    "scale_final = nn.Parameter(torch.ones(GPT_CONFIG_124M[\"emb_dim\"]))\n",
    "shift_final = nn.Parameter(torch.zeros(GPT_CONFIG_124M[\"emb_dim\"]))\n",
    "\n",
    "mean = shortcut_result_2.mean(dim=-1,keepdim=True) # mean before layerNorm\n",
    "var = shortcut_result_2.var(dim=-1,keepdim=True)   # variance before LayerNorm\n",
    "print(\"[before LayerNorm] mean :\",mean)\n",
    "print(\"[before LayerNorm] var :\",torch.sqrt(var))\n",
    "\n",
    "print(\"-\"*50)\n",
    "\n",
    "layernorm_result_naive_final = (shortcut_result_2 - mean) / torch.sqrt(var + eps)\n",
    "mean = layernorm_result_naive_final.mean(dim=-1,keepdim=True) # mean after layerNorm\n",
    "var = layernorm_result_naive_final.var(dim=-1,keepdim=True)   # variance after LayerNorm\n",
    "print(\"[after LayerNorm] mean :\",mean)\n",
    "print(\"[after LayerNorm] var :\",torch.sqrt(var))\n",
    "\n",
    "layernorm_result_final = scale_final * layernorm_result_naive_final + shift_final\n",
    "print(\"LayerNorm result: \",layernorm_result_final,layernorm_result_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer: project result to vocab size logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model output:  tensor([[[-0.0912, -0.4733,  0.5195,  ..., -0.7332, -1.0550, -0.8636],\n",
      "         [ 0.4925, -0.0938, -0.1721,  ..., -0.0998,  0.2614,  0.0258],\n",
      "         [ 0.0129, -0.1933,  0.3204,  ...,  0.1586, -0.4201,  0.3723],\n",
      "         [ 1.1929, -0.1604,  1.0917,  ...,  0.1996,  0.8766, -1.6754],\n",
      "         [-0.9656,  0.0564,  0.1322,  ...,  0.4414, -0.0039, -0.1358],\n",
      "         [ 0.2202, -0.3058,  0.5253,  ...,  0.1822, -0.0514, -0.4342]]],\n",
      "       grad_fn=<UnsafeViewBackward0>) torch.Size([1, 6, 50257])\n"
     ]
    }
   ],
   "source": [
    "output_proj = nn.Linear(GPT_CONFIG_124M[\"emb_dim\"],GPT_CONFIG_124M[\"vocab_size\"],bias=False)\n",
    "model_output = output_proj(layernorm_result_final)\n",
    "print(\"model output: \",model_output,model_output.shape)\n",
    "# up to here the original sequence has been shifted by model and predict one new token. The output has same seq length with input, except the ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2202, -0.3058,  0.5253,  ...,  0.1822, -0.0514, -0.4342]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = model_output[:,-1,:] # get the last token in seq\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zzi'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas = torch.softmax(logits,dim=-1)\n",
    "idx_next = torch.argmax(probas,dim=-1,keepdim=True)\n",
    "tokenizer.decode(idx_next.detach().numpy().tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I HAD always thought Jack', 'zzi']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode_batch(inputs.detach().numpy().tolist()+idx_next.detach().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' HAD always thought Jack G']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode_batch(targets.detach().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdchat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
